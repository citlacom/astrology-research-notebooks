{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64196db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 9\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "\n",
    "import random\n",
    "random.seed(SEED)\n",
    "\n",
    "import numpy as np\n",
    "rng = np.random.default_rng(SEED) \n",
    "ss = rng.bit_generator._seed_seq # use for multiprocessing\n",
    "\n",
    "from neuralprophet import set_random_seed\n",
    "set_random_seed(SEED)\n",
    "\n",
    "SEED_states_log = []\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------------------\n",
    "import sys\n",
    "print(sys.version)\n",
    "import collections\n",
    "from pprint import pprint as pp\n",
    "from functools import reduce\n",
    "import multiprocessing\n",
    "import concurrent.futures\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statistics import mean, median, mode\n",
    "from scipy import stats\n",
    "from scipy.special import boxcox1p, inv_boxcox1p\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "\n",
    "tickers = (\n",
    "\"BTC\",\n",
    "\"ETH\",\n",
    ")\n",
    "\n",
    "pov = (\n",
    "# 'Astro'\n",
    "# 'Astro_Geo'\n",
    "'Astro_Helio'\n",
    ")\n",
    "\n",
    "usdpairs = tickers\n",
    "\n",
    "# usdpairs = (\n",
    "# \"BTC\",\n",
    "# \"RealEstate\",\n",
    "# \"S&P\",\n",
    "# \"Crude\",\n",
    "# \"Gold\",\n",
    "# \"Silver\",\n",
    "# \"Dollar\",\n",
    "# \"Bond\",\n",
    "# \"Volatility\",\n",
    "# )\n",
    "\n",
    "maxint = 9\n",
    "\n",
    "def vortex(n):\n",
    "#     return sum([int(x) for x in list(str(abs(int(float(str(n).replace(\".\",\"\"))))))])\n",
    "    return sum([int(x) for x in list(str(abs(int(float(n)))))])\n",
    "\n",
    "def blackhole(n):\n",
    "    if n > 0:\n",
    "        if vortex(n) > maxint:\n",
    "            return blackhole(vortex(n))\n",
    "        if vortex(n) <= maxint:\n",
    "            return vortex(n)\n",
    "    else:\n",
    "        if vortex(n) > maxint:\n",
    "            return blackhole(vortex(n))*-1\n",
    "        if vortex(n) <= maxint:\n",
    "            return vortex(n)*-1\n",
    "\n",
    "def log_transform(df):\n",
    "    # copy the dataframe\n",
    "    tdf = df.copy()\n",
    "    # apply log scaling\n",
    "    for column in tdf.columns:\n",
    "        tdf[column] = np.log(tdf[column])\n",
    "\n",
    "    tdf.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    tdf = tdf.astype(float)\n",
    "    tdf = tdf.interpolate(method='linear', axis=0).ffill().bfill()\n",
    "#     tdf = tdf.dropna(axis='columns')\n",
    "    tdf = tdf.fillna(0)\n",
    "\n",
    "    return tdf\n",
    "\n",
    "\n",
    "def boxcox(df):\n",
    "    # copy the dataframe\n",
    "    _df = df.copy()\n",
    "\n",
    "    # apply log scaling\n",
    "    for column in _df.columns:\n",
    "\n",
    "#         tdf[column] = stats.boxcox(tdf[column])\n",
    "        _df[column] = boxcox1p(_df[column], 0.25)\n",
    "\n",
    "#     _df = _df.dropna(axis='columns')\n",
    "    _df = _df.fillna(0)\n",
    "    _df = _df.astype(float)\n",
    "\n",
    "    return _df\n",
    "\n",
    "def inv_boxcox(df):\n",
    "    # copy the dataframe\n",
    "    _df = df.copy()\n",
    "\n",
    "    # apply log scaling\n",
    "    for column in _df.columns:\n",
    "\n",
    "#         tdf[column] = stats.boxcox(tdf[column])\n",
    "        _df[column] = inv_boxcox1p(_df[column], 0.25)\n",
    "\n",
    "#     _df = _df.dropna(axis='columns')\n",
    "    _df = _df.fillna(0)\n",
    "    _df = _df.astype(float)\n",
    "\n",
    "    return _df\n",
    "\n",
    "\n",
    "def min_max_scaling(df):\n",
    "    # copy the dataframe\n",
    "    tdf = df.copy()\n",
    "    # apply min-max scaling\n",
    "    for column in tdf.columns:\n",
    "        tdf[column] = (tdf[column] - tdf[column].min()) / (tdf[column].max() - tdf[column].min())\n",
    "#     tdf = tdf.dropna(axis='columns')\n",
    "    tdf = tdf.fillna(0)\n",
    "    return tdf\n",
    "\n",
    "\n",
    "def dfta(ticker):\n",
    "\n",
    "    path = '///'\n",
    "    \n",
    "    if ticker in usdpairs:\n",
    "        # Loading the dataset\n",
    "        file = ticker + \".csv\"\n",
    "        url = path + file\n",
    "        df = pd.read_csv(url,parse_dates = True,index_col=0)\n",
    "    else:\n",
    "        file = \"BTC.csv\"\n",
    "        url = path + file\n",
    "        c = pd.read_csv(url,parse_dates = True,index_col=0)\n",
    "        c = c.rename(columns={\"open\": \"o\",\n",
    "                              \"high\": \"h\",\n",
    "                              \"low\": \"l\",\n",
    "                              \"close\": \"c\"})\n",
    "\n",
    "        # Loading the dataset\n",
    "        file = ticker + \".csv\"\n",
    "        url = path + file\n",
    "        df = pd.read_csv(url,parse_dates = True,index_col=0)\n",
    "\n",
    "        df = pd.merge(df, c,left_index=True,right_index=True)\n",
    "\n",
    "\n",
    "\n",
    "        df[\"open\"] = df[\"open\"].div(df[\"o\"])\n",
    "        df[\"high\"] = df[\"high\"].div(df[\"h\"])\n",
    "        df[\"low\"] = df[\"low\"].div(df[\"l\"])\n",
    "        df[\"close\"] = df[\"close\"].div(df[\"c\"])\n",
    "\n",
    "        df = df.drop([\n",
    "              'o',\n",
    "              'h',\n",
    "              'l',\n",
    "              'c',\n",
    "             ] , axis='columns')\n",
    "\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    df['y'] = df[[\"open\", \"close\"]].sum(axis=1).div(2) # (o+c)/2\n",
    "\n",
    "    df = boxcox(df)\n",
    "    df = log_transform(df)\n",
    "    df = boxcox(df)\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "#######################################################################################################\n",
    "\n",
    "#     start_date = \"1999-01-01\"\n",
    "#     end_date = \"2020-01-01\"\n",
    "# #     end_date = \"2020-07-19\"\n",
    "# #     end_date = \"2020-08-27\"\n",
    "# #     end_date = \"2021-01-01\"\n",
    "# #     end_date = \"2021-05-01\"\n",
    "#\n",
    "#     after_start_date = df.index >= start_date\n",
    "#     before_end_date = df.index <= end_date\n",
    "#     between_two_dates = after_start_date & before_end_date\n",
    "#     df = df.loc[between_two_dates]\n",
    "\n",
    "#######################################################################################################\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "    sun = '///SN_d_tot_V2.0.csv'\n",
    "    sf = pd.read_csv(sun,parse_dates = True,index_col=0)\n",
    "    df = pd.merge(df, sf,left_index=True,right_index=True)\n",
    "\n",
    "    for _ in sf:\n",
    "        df[\"d_\" + _ ] = df[\"y\"].div(df[[\"y\", _]].sum(axis=1))\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "    ki = '///k-indices.csv'\n",
    "    kf = pd.read_csv(ki,parse_dates = True,index_col=0)\n",
    "    df = pd.merge(df, kf,left_index=True,right_index=True)\n",
    "\n",
    "    for _ in kf:\n",
    "        df[\"d_\" + _ ] = df[\"y\"].div(df[[\"y\", _]].sum(axis=1))\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "    file = pov + \".csv\"\n",
    "    url = '///' + file\n",
    "    astro = pd.read_csv(url,parse_dates = True,index_col=0)\n",
    "    astro = astro[~astro.index.duplicated()]\n",
    "#     astro.columns=['ch' + str(x) for x in range(len(astro.columns))]\n",
    "    df = pd.merge(df, astro,left_index=True,right_index=True)\n",
    "\n",
    "    for _ in astro:\n",
    "        df[\"d_\" + _ ] = df[\"y\"].div(df[[\"y\", _]].sum(axis=1))\n",
    "#@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "    df = df.tail(1884)\n",
    "    df = df.head(1883)\n",
    "\n",
    "#     df = df.tail(2001)\n",
    "#     df = df.head(2000)\n",
    "\n",
    "    print(ticker)\n",
    "    print(len(df))\n",
    "#@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "    df['ds'] = df.index.copy()\n",
    "\n",
    "    earliest = df.iloc[:1]['ds']\n",
    "    earliest = pd.to_datetime(earliest).reset_index(drop=True)[0]\n",
    "    earliest = earliest.strftime('%Y-%m-%d')\n",
    "\n",
    "    latest = df.iloc[-1:]['ds']\n",
    "    latest = pd.to_datetime(latest).reset_index(drop=True)[0]\n",
    "    latest = latest.strftime('%Y-%m-%d')\n",
    "\n",
    "    print(earliest,latest)\n",
    "\n",
    "    # gap check\n",
    "    all_dates = pd.date_range(start=earliest, end=latest)\n",
    "    complete_dates = list(all_dates.strftime('%Y-%m-%d'))\n",
    "    questionable_dates = list(df[\"ds\"])\n",
    "\n",
    "    for i in complete_dates:\n",
    "        if i not in questionable_dates:\n",
    "            pass\n",
    "        else:\n",
    "            print(\"%%%%%%%%%%%%%%%%%%%%%% PROBLEM WITH DATE GAP %%%%%%%%%%%%%%%%%%%%%%\")\n",
    "\n",
    "    df = df.drop([\n",
    "      'ds',\n",
    "     ] , axis='columns')\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    print(df.columns[df.isna().any()].tolist())\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    tdf = df.applymap(lambda x: blackhole(x))\n",
    "    tdf.columns=['z' + str(x) for x in range(len(tdf.columns))]\n",
    "#     tdf = tdf.dropna(axis='columns')\n",
    "    tdf = tdf.fillna(0)\n",
    "    df = pd.merge(df, tdf,left_index=True,right_index=True)\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "#     df = boxcox(df)\n",
    "#     df = log_transform(df)\n",
    "    df = min_max_scaling(df)\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    df = df.loc[:,df.apply(pd.Series.nunique) > 2]\n",
    "\n",
    "    path = '///'\n",
    "    file = ticker + \"Backup.csv\"\n",
    "    out = path + file\n",
    "    df.to_csv(out,index=False)\n",
    "\n",
    "    file = \"_\" + ticker + \".csv\"\n",
    "    out = path + file\n",
    "    df.to_csv(out,index=True)\n",
    "    print(len(df.columns))\n",
    "\n",
    "\n",
    "#     fig, ax = plt.subplots(figsize=(16,9))\n",
    "#     df[\"y\"].plot(xlabel=\"\\nCreated on \"+latest, ylabel=\"Scale\\n\", ax=ax)\n",
    "#     ax.xaxis.label.set_size(20)\n",
    "#     ax.yaxis.label.set_size(20)\n",
    "#     ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "#     ax.set_title(ticker, fontsize=20, fontweight=\"bold\")\n",
    "\n",
    "# dfta(\"BTC\")\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "# with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    executor.map(dfta,tickers)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
